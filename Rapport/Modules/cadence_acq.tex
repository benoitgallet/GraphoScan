Naturellement, différentes idées nous sont venues pour augmenter la cadence d'acquisition de la vidéo en stéréo. Le programme fonctionne suivant plusieurs étapes~: Tout d'abord, une image est capturée à partir des deux caméras, puis les deux images sont encodées dans une vidéo. Une fois la capture finie, la vidéo est traitée afin de régler les problèmes de distorsion. Grâce à cette grande boucle qui capture les images deux par deux (une image par caméra), les vidéos des caméras sont synchronisées (la xième image de chaque vidéo est datée du même instant, à une latence près), et permettent donc d'avoir simultanément la feuille d'écriture filmée sous deux angles différents. La modélisation en 3D sous OpenGL est alors possible. La seule variable est que plus la cadence d'acquisition est élevée, plus il y aura de FPS (Frame Per Second) sur les vidéos finales, et plus la modélisation 3D de la plume sera précise. De plus, notre architecture et notre code devaient être assez robustes, pour que si un jour une troisième voire une quatrième caméra sont rajoutées, le nombre de FPS ne redescende pas drastiquement.

\subsubsection{Programmation parallèle}

Grâce à la programmation parallèle, qu'elle soit au niveau du CPU avec de l'OpenMP ou des threads, ou au niveau du GPU avec CUDA, nous pensions pouvoir accélérer l'acquisition des images, et donc des FPS sur les vidéos finales. Nous pensions regarder quelles parties pouvaient être faites en parallèle, peut-être est-il possible d'uniquement récupérer une image tous les trois centièmes de secondes (pour les 30 fps) dans le programme principal, et de faire tous les autres traitements dans des régions parallèles, avec par exemple un thread qui s'occupe d'ajouter la prochaine image à la vidéo, un autre thread qui enlève la distorsion de l'image, etc.

\subsubsection{Complexité}

Reprendre le code pour en examiner sa complexité était une autre piste envisagée pour augmenter les FPS. Nous pensions séparer cette idée en deux étapes~: Tout d'abord regarder la complexité de l'algorithme dans sa globalité, pour se rendre compte s'il y a problème ou non à ce niveau là, et voir les morceaux posant plus problème que le reste, puis faire des tests plus précisément sur ces parties pour voir ce qui ne va pas. Une analyse légerement différente pouvait être effectuée, avec des tests fontionnels calculant quelle partie prend le plus de temps. Ces tests sont très complémentaires de ceux de complexité, à eux deux ils devaient mettre en exergue les problèmes principaux du code.

\subsubsection{Modularité}

Outre cette analyse de la complexité, une mise au propre du code devait être effectuée. En effet, tout se trouve dans la fonction \texttt{main}, dans deux grandes boucles. Une partie de notre travail était donc de modulariser cette fonction, de la séparer en plusieurs méthodes afin de gagner en clarté. Nous avons par la suite utilisé l'option de compilation \texttt{-O3} pour faire de l'inlining, ce qui permet de remplacer l'appel du fonction par le corps de celle-ci, permettant de minimiser le coût de cette modularisation du code lors de son exécution.

\subsubsection{Généralisation}

Sinon, le dernier axe sur lequel nous avons travaillé a été la généralisation du nombre de caméras. A l'origine, tout dans le code était fait pour deux caméras, avec du code dupliqué pour chaque action. La généralisation pour \textit{n} caméras sera facilitée par la modularisation du code, et permettra par la suite de rajouter une ou plusieurs caméras sans modification majeure, uniquement en changeant quelques \texttt{\#define}.
