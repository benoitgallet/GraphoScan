\subsection{Droits d'auteur}
Au fur et à mesure que nous essayions de comprendre le code de la reconstruction 3D (ce qui a été long car il a été fourni sans doc, commentaires et explications d'utilisation, avec une syntaxe et des imports pour Windows), nous nous sommes rendu compte que sur cette partie plusieurs morceaux de code avaient été copiés sur Internet.

La classe Shader, ainsi que la moitié de la classe Camera provient de \url{http://blog.csdn.net/sinat_26989191/article/details/51205149}, un outil pour faire un système solaire en 3D.

La classe HOG est presque entièrement copiéé-collée de la fin de ce programme ( \url{http://lib.csdn.net/snippet/cplusplus/28974} ), qui est sous copyright.

Diverses autres parties du code proviennent de copiés-collés de différentes documentations ou exemples, ce qui est dans une certaine mesure moins dé\-ran\-geant.

Il y a certainement d'autres endroits du projet qui proviennent d'Internet, tout n'a pas été vérifié par manque de temps. Au total, nous estimons qu'au moins 50\% du code n'a pas été écrit par le groupe précédent. Cela implique que si ce projet est repris par un groupe futur, il faudra réécrire ces parties du code, ou du moins indiquer clairement les sources et les différents copyrights sur les classes copiées.

\subsection{Interface graphique}

Une extension possible serait de réaliser une interface graphique, par exemple en Qt. Cela permettrait un maniement beaucoup plus facile de l'application, et rendrait possible son utilisation par des personnes extérieures. En effet, en ce moment tout s'exécute dans le terminal, ce qui peut être moins intuitif. Avec cette interface graphique, on pourrait par exemple choisir de sélectionner une caméra pour voir ce qu'elle enregistre, définir différentes options comme choisir l'algorithme de tracking à utiliser, les sorties vidéos ou images à effectuer, ...

\subsection{Bouger la feuille}

La dernière amélioration à apporter au code serait de pouvoir bouger la feuille. Une technique possible serait de faire du multi-tracking sur deux points. En effet, en dessinant juste deux points noirs sur la feuille et en faisant du tracking dessus, on serait capable de détecter tout mouvement ou rotation de la feuille. Il suffira donc par la suite d'appliquer une translation aux coordonnées de l'écriture par rapport à celle de ces deux points pour pouvoir avoir une image qui colle plus à la réalité.

\subsection{Synchronisation native}
En naviguant sur la documentation de PointGrey (le fabricant des caméras), nous nous sommes rendu compte qu'il existait déjà un moyen de faire de l'ac\-qui\-si\-tion stéréo (\cite{stereo_pt}), grâce à des fonctions dans l'API fournie, et à un cable reliant les caméras. Peut-être faudrait-il envisager aussi cette solution dans le futur, même si notre travail d'amélioration du code de l'étudiant précédent s'étant occupé de cette partie est désormais fini. Il y aurait donc peut-être moyen dans le futur de supprimer la partie de l'acquisition vidéos, et de juste utiliser la deuxième phase du code, avec un peu de modifications pour intégrer cette acquisition native avant. Cela permettrait d'avoir une application en un bloc, plutôt que séparée comme actuellement.

\subsection{Reconstruction 3D à n caméras}
Comme dit dans le bilan, la fonction qui met en relation des points en 2D pour faire des points 3D ne prend que deux caméras. Pour modifier cela, il faudrait changer la méthode de reconstruction 3D de points qui actuellement ne prend les points que de deux caméras. Une autre solution serait de lancer le programme sur toutes les paires de caméras et de faire ensuite la moyenne des points récoltés pour plus de réalisme dans la reconstruction.